# XR-1 æ¨¡å‹ä½¿ç”¨æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **é€‚ç”¨å¯¹è±¡**: å¤©å·¥Proæœºå™¨äºº (Tiankung Pro)  
> **æœ€åæ›´æ–°**: 2026-02-02

---

## ğŸ“‹ ç›®å½•

1. [XR-1 ç®€ä»‹](#ä¸€-xr-1-ç®€ä»‹)
2. [å¿«é€Ÿå¼€å§‹](#äºŒ-å¿«é€Ÿå¼€å§‹)
3. [æ¨¡å‹æ¨ç†](#ä¸‰-æ¨¡å‹æ¨ç†)
4. [æ¨¡å‹å¾®è°ƒ](#å››-æ¨¡å‹å¾®è°ƒ)
5. [çœŸå®æœºå™¨äººéƒ¨ç½²](#äº”-çœŸå®æœºå™¨äººéƒ¨ç½²)
6. [æ•…éšœæ’æŸ¥](#å…­-æ•…éšœæ’æŸ¥)

---

## ä¸€ã€XR-1 ç®€ä»‹

### 1.1 ä»€ä¹ˆæ˜¯XR-1ï¼Ÿ

XR-1æ˜¯**åŒ—äº¬äººå½¢æœºå™¨äººåˆ›æ–°ä¸­å¿ƒ**å¼€å‘çš„å®˜æ–¹VLAï¼ˆVision-Language-Actionï¼‰å¤§æ¨¡å‹ï¼Œä¸“ä¸ºå…·èº«æ™ºèƒ½è®¾è®¡ã€‚

**æ ¸å¿ƒèƒ½åŠ›**:
- ğŸ¯ å°†è§†è§‰è§‚æµ‹ + è¯­è¨€æŒ‡ä»¤ â†’ è½¬åŒ–ä¸ºç‰©ç†åŠ¨ä½œ
- ğŸ¦¾ æ”¯æŒåŒè‡‚åè°ƒæ“ä½œ
- ğŸ”„ è·¨æœºå™¨äººæœ¬ä½“æ³›åŒ–ï¼ˆå¤©å·¥ã€Frankaã€UR5ç­‰ï¼‰

### 1.2 æŠ€æœ¯æ¶æ„

```
è¾“å…¥: [å›¾åƒ] + [è¯­è¨€æŒ‡ä»¤] + [æœºå™¨äººçŠ¶æ€]
        â†“
   UVMCç¼–ç å™¨ (ç»Ÿä¸€è§†åŠ¨è¡¨å¾)
        â†“
   è‡ªå›å½’Transformer
        â†“
è¾“å‡º: [åŒè‡‚å…³èŠ‚åŠ¨ä½œ]
```

**ä¸‰é˜¶æ®µè®­ç»ƒ**:

| é˜¶æ®µ | åç§° | åŠŸèƒ½ | æ•°æ®é‡ | ç”¨é€” |
|------|------|------|--------|------|
| Stage 1 | UVMCå­¦ä¹  | è§†è§‰-åŠ¨ä½œç»Ÿä¸€è¡¨å¾ | EGO4D + æœºå™¨äººæ•°æ® | é¢„è®­ç»ƒ |
| Stage 2 | é¢„è®­ç»ƒ | é€šç”¨æ“ä½œçŸ¥è¯† | RoboMIND 2.0 (30ä¸‡+è½¨è¿¹) | é€šç”¨æŠ€èƒ½ |
| Stage 3 | ä»»åŠ¡å¾®è°ƒ | ç‰¹å®šä»»åŠ¡é€‚é… | 50-100æ¡ä»»åŠ¡è½¨è¿¹ | **æ¨èä½¿ç”¨** |

### 1.3 è¾“å…¥è¾“å‡ºæ ¼å¼

**è¾“å…¥**:
```python
{
    "task": "æ‹¿èµ·çº¢è‰²çš„æ¯å­",           # è¯­è¨€æŒ‡ä»¤
    "observation.images.image_0": tensor,  # å¤´éƒ¨ç›¸æœºå›¾åƒ [1, 3, H, W]
    "observation.images.image_1": tensor,  # å·¦è…•ç›¸æœºå›¾åƒ [1, 3, H, W]
    "observation.images.image_2": tensor,  # å³è…•ç›¸æœºå›¾åƒ [1, 3, H, W]
    "observation.state.arm_joint_position": tensor  # å…³èŠ‚çŠ¶æ€ [1, 12]
}
```

**è¾“å‡º**:
```python
action_queue  # åŠ¨ä½œåºåˆ— [action_horizon, 12]
              # 12 = å·¦è‡‚6å…³èŠ‚ + å³è‡‚6å…³èŠ‚
```

---

## äºŒã€å¿«é€Ÿå¼€å§‹

### 2.1 ç¯å¢ƒå‡†å¤‡

```bash
# SSHåˆ°DGX Spark
ssh spark

# æ¿€æ´»XR-1ç¯å¢ƒ
source /home/leo/miniconda3/etc/profile.d/conda.sh
conda activate xr1

# éªŒè¯ç¯å¢ƒ
python -c "from lerobot.common.policies.xr1.modeling_xr1_stage2 import Xr1Stage2Policy; print('âœ… ç¯å¢ƒæ­£å¸¸')"
```

### 2.2 æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹

```bash
# æŸ¥çœ‹å·²ä¸‹è½½çš„æ¨¡å‹
ls -lh ~/projects/XR-1/pretrained/

# é¢„æœŸè¾“å‡º:
# XR-1-Stage1-UVMC/  (3.9GB)
# XR-1-Stage2/       (16GB)
```

---

## ä¸‰ã€æ¨¡å‹æ¨ç†

### 3.1 åŸºç¡€æ¨ç†ç¤ºä¾‹

```python
import torch
import cv2
import numpy as np
from lerobot.common.policies.xr1.modeling_xr1_stage2 import Xr1Stage2Policy

# 1. åŠ è½½æ¨¡å‹
model_path = "/home/leo/projects/XR-1/pretrained/XR-1-Stage2"
device = "cuda"

policy = Xr1Stage2Policy.from_pretrained(model_path, map_location=device)
policy.eval()

# 2. å‡†å¤‡è¾“å…¥æ•°æ®
task_name = "æ‹¿èµ·çº¢è‰²çš„æ¯å­"

# å›¾åƒè¾“å…¥ (ç¤ºä¾‹ä½¿ç”¨éšæœºå›¾åƒï¼Œå®é™…åº”ä½¿ç”¨ç›¸æœºæ•è·)
images = {
    "image_0": torch.randn(1, 3, 480, 640).to(device),  # å¤´éƒ¨ç›¸æœº
    "image_1": torch.randn(1, 3, 480, 640).to(device),  # å·¦è…•ç›¸æœº
    "image_2": torch.randn(1, 3, 480, 640).to(device),  # å³è…•ç›¸æœº
}

# æœºå™¨äººçŠ¶æ€ (12ç»´: å·¦è‡‚6å…³èŠ‚ + å³è‡‚6å…³èŠ‚)
state = torch.randn(1, 12).to(device)

# 3. æ„å»ºè§‚æµ‹å­—å…¸
observation = {
    "task": [task_name],
    "observation.images.image_0": images["image_0"],
    "observation.images.image_1": images["image_1"],
    "observation.images.image_2": images["image_2"],
    "observation.state.arm_joint_position": state,
}

# 4. æ¨ç†
action_horizon = 50  # é¢„æµ‹æœªæ¥50æ­¥åŠ¨ä½œ
with torch.no_grad():
    actions = policy.select_action(observation, action_horizon=action_horizon)

print(f"è¾“å‡ºåŠ¨ä½œå½¢çŠ¶: {actions.shape}")  # [50, 12]
print(f"åŠ¨ä½œèŒƒå›´: [{actions.min():.3f}, {actions.max():.3f}]")
```

### 3.2 ä½¿ç”¨XR1_Evaluationç±»ï¼ˆæ¨èï¼‰

```python
# æ–‡ä»¶: ~/projects/XR-1/deploy/real_robot/xr1_deploy.py

from xr1_deploy import XR1_Evaluation

# åˆå§‹åŒ–è¯„ä¼°å™¨
evaluator = XR1_Evaluation(
    model_path="/home/leo/projects/XR-1/pretrained/XR-1-Stage2",
    robot_type="tiankung",  # æˆ– "franka"
    action_horizon=50,
    exp_weight=0.05,
    ensemble=True,
)

# å‡†å¤‡è§‚æµ‹æ•°æ®
obs = {
    "images": {
        "head": encoded_head_image,      # å¤´éƒ¨ç›¸æœºJPEGç¼–ç 
        "left_wrist": encoded_left_img,  # å·¦è…•ç›¸æœºJPEGç¼–ç 
        "right_wrist": encoded_right_img,# å³è…•ç›¸æœºJPEGç¼–ç 
    },
    "arm_joints": {
        "left": left_arm_joints,   # numpyæ•°ç»„ [6]
        "right": right_arm_joints, # numpyæ•°ç»„ [6]
    }
}

# æ¨ç†
task_name = "æ‹¿èµ·çº¢è‰²çš„æ¯å­"
actions = evaluator.Inference_Dual_Arm_Tien_Kung2(obs, task_name)

# actions: [action_horizon, 12] çš„åŠ¨ä½œåºåˆ—
```

### 3.3 å›¾åƒé¢„å¤„ç†

```python
def preprocess_image(image_np, target_size=(640, 480)):
    """
    å›¾åƒé¢„å¤„ç†æµç¨‹
    
    Args:
        image_np: numpyæ•°ç»„ [H, W, 3] (BGRæ ¼å¼ï¼ŒOpenCVè¯»å–)
        target_size: (width, height)
    
    Returns:
        tensor: [1, 3, H, W] å½’ä¸€åŒ–åçš„tensor
    """
    # 1. Resize
    image_resized = cv2.resize(image_np, target_size)
    
    # 2. è½¬æ¢ä¸ºRGB
    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)
    
    # 3. å½’ä¸€åŒ–åˆ°[0, 1]
    image_norm = image_rgb.astype(np.float32) / 255.0
    
    # 4. è½¬æ¢ä¸ºtensor [H, W, 3] -> [3, H, W]
    image_tensor = torch.from_numpy(image_norm).permute(2, 0, 1)
    
    # 5. æ·»åŠ batchç»´åº¦ [1, 3, H, W]
    image_tensor = image_tensor.unsqueeze(0).to("cuda")
    
    return image_tensor
```

---

## å››ã€æ¨¡å‹å¾®è°ƒ

### 4.1 å‡†å¤‡æ•°æ®é›†

**æ•°æ®æ ¼å¼**: LeRobot Dataset v2.1

```bash
# ç›®å½•ç»“æ„
~/projects/XR-1/data/lerobot_tiankung/
â”œâ”€â”€ meta/
â”‚   â”œâ”€â”€ info.json
â”‚   â”œâ”€â”€ stats.json
â”‚   â””â”€â”€ tasks.json
â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ observation.images.image_0/
â”‚   â”œâ”€â”€ observation.images.image_1/
â”‚   â””â”€â”€ observation.images.image_2/
â””â”€â”€ data/
    â”œâ”€â”€ chunk-000/...
```

### 4.2 æ‰§è¡Œå¾®è°ƒï¼ˆStage 3ï¼‰

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd ~/projects/XR-1

# æ¿€æ´»ç¯å¢ƒ
source /home/leo/miniconda3/etc/profile.d/conda.sh
conda activate xr1

# è¿è¡Œå¾®è°ƒè„šæœ¬
bash scripts/xr1_stage3_finetune.sh \
    --dataset lerobot_tiankung \
    --real
```

**å…³é”®å‚æ•°è¯´æ˜**:

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--policy.stage2_pretrained_path` | `../pretrained/XR-1-Stage2` | Stage2é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ |
| `--policy.action_chunk_size` | 50 | åŠ¨ä½œé¢„æµ‹é•¿åº¦ |
| `--policy.freeze_vision_encoder` | true | æ˜¯å¦å†»ç»“è§†è§‰ç¼–ç å™¨ |
| `--policy.freeze_language_encoder` | true | æ˜¯å¦å†»ç»“è¯­è¨€ç¼–ç å™¨ |
| `--policy.optimizer_lr` | 5e-5 | å­¦ä¹ ç‡ |
| `--batch_size` | 20 | æ‰¹æ¬¡å¤§å° |
| `--steps` | 50_000 | è®­ç»ƒæ­¥æ•° |

### 4.3 è°ƒè¯•æ¨¡å¼

```bash
# å¿«é€Ÿè°ƒè¯•ï¼ˆä¸ä¿å­˜æ¨¡å‹ï¼Œç”¨äºéªŒè¯ä»£ç ï¼‰
bash scripts/xr1_stage3_finetune.sh \
    --dataset lerobot_tiankung \
    --debug
```

### 4.4 ç›‘æ§è®­ç»ƒ

```bash
# æ–¹æ³•1: TensorBoard
tensorboard --logdir=~/projects/XR-1/save_xr1/xr1_stage3/

# æ–¹æ³•2: Weights & Biases (å·²é…ç½®)
# è®­ç»ƒæ—¥å¿—ä¼šè‡ªåŠ¨ä¸Šä¼ åˆ° https://wandb.ai
```

---

## äº”ã€çœŸå®æœºå™¨äººéƒ¨ç½²

### 5.1 ç½‘ç»œé…ç½®

```bash
# 1. é…ç½®DGX Sparkç½‘ç»œæ¥å£
sudo ip addr add 192.168.41.100/24 dev enp1s0f0np0
sudo ip link set enp1s0f0np0 up

# 2. æµ‹è¯•è¿æ¥
ping 192.168.41.1  # æœºå™¨äººIP

# 3. SSHç™»å½•æœºå™¨äºº
ssh ubuntu@192.168.41.1
```

### 5.2 å¯åŠ¨æœºå™¨äººé©±åŠ¨

åœ¨**æœºå™¨äºº**ä¸Šæ‰§è¡Œï¼š

```bash
# ç»ˆç«¯1: å¯åŠ¨æœ¬ä½“é©±åŠ¨
ros2 launch body_control body.launch.py

# ç»ˆç«¯2: å¯åŠ¨è¿æ§
ros2 launch motion_control motion.py
```

### 5.3 è¿è¡Œéƒ¨ç½²è„šæœ¬

åœ¨**DGX Spark**ä¸Šæ‰§è¡Œï¼š

```bash
# æ¿€æ´»ç¯å¢ƒ
source /home/leo/miniconda3/etc/profile.d/conda.sh
conda activate xr1

# è¿è¡Œéƒ¨ç½²
cd ~/projects/XR-1
python deploy/real_robot/xr1_deploy.py \
    --config configs/tiankung/tiankung_pro.yaml \
    --checkpoint pretrained/XR-1-Stage2 \
    --robot_type tiankung
```

### 5.4 å®Œæ•´éƒ¨ç½²ä»£ç ç¤ºä¾‹

```python
#!/usr/bin/env python3
"""
XR-1 å¤©å·¥Proéƒ¨ç½²ç¤ºä¾‹
"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, JointState
from std_msgs.msg import Float64MultiArray
import cv2
import torch
import numpy as np
from cv_bridge import CvBridge

from deploy.real_robot.xr1_deploy import XR1_Evaluation

class XR1DeploymentNode(Node):
    def __init__(self):
        super().__init__('xr1_deployment')
        
        # åˆå§‹åŒ–XR-1æ¨¡å‹
        self.evaluator = XR1_Evaluation(
            model_path="/home/leo/projects/XR-1/pretrained/XR-1-Stage2",
            robot_type="tiankung",
            action_horizon=50,
            exp_weight=0.05,
            ensemble=True,
        )
        
        # CVæ¡¥æ¥
        self.bridge = CvBridge()
        
        # è®¢é˜…ç›¸æœºè¯é¢˜
        self.sub_head = self.create_subscription(
            Image, '/camera/nav/color/image_raw', 
            self.head_callback, 10)
        self.sub_left = self.create_subscription(
            Image, '/camera/left_wrist/color/image_raw',
            self.left_callback, 10)
        self.sub_right = self.create_subscription(
            Image, '/camera/right_wrist/color/image_raw',
            self.right_callback, 10)
        
        # è®¢é˜…å…³èŠ‚çŠ¶æ€
        self.sub_joints = self.create_subscription(
            JointState, '/human_arm_state_left',
            self.joints_callback, 10)
        
        # å‘å¸ƒæ§åˆ¶æŒ‡ä»¤
        self.pub_left = self.create_publisher(
            Float64MultiArray, '/human_arm_ctrl_left', 10)
        self.pub_right = self.create_publisher(
            Float64MultiArray, '/human_arm_ctrl_right', 10)
        
        # å­˜å‚¨æœ€æ–°æ•°æ®
        self.images = {}
        self.joints = None
        self.task_name = "æ‹¿èµ·çº¢è‰²çš„æ¯å­"  # å½“å‰ä»»åŠ¡
        
        # æ§åˆ¶å¾ªç¯
        self.timer = self.create_timer(0.05, self.control_loop)  # 20Hz
        
    def head_callback(self, msg):
        cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        _, encoded = cv2.imencode('.jpg', cv_image)
        self.images['head'] = encoded
        
    def left_callback(self, msg):
        cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        _, encoded = cv2.imencode('.jpg', cv_image)
        self.images['left_wrist'] = encoded
        
    def right_callback(self, msg):
        cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        _, encoded = cv2.imencode('.jpg', cv_image)
        self.images['right_wrist'] = encoded
        
    def joints_callback(self, msg):
        self.joints = np.array(msg.position)
        
    def control_loop(self):
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å°±ç»ª
        if len(self.images) < 3 or self.joints is None:
            return
            
        # æ„å»ºè§‚æµ‹
        obs = {
            "images": self.images,
            "arm_joints": {
                "left": self.joints[:6],
                "right": self.joints[6:12],
            }
        }
        
        # æ¨ç†
        actions = self.evaluator.Inference_Dual_Arm_Tien_Kung2(
            obs, self.task_name)
        
        # å‘å¸ƒæ§åˆ¶æŒ‡ä»¤ (å–ç¬¬ä¸€ä¸ªåŠ¨ä½œ)
        left_cmd = Float64MultiArray()
        left_cmd.data = actions[0, :6].tolist()
        right_cmd = Float64MultiArray()
        right_cmd.data = actions[0, 6:12].tolist()
        
        self.pub_left.publish(left_cmd)
        self.pub_right.publish(right_cmd)
        
        self.get_logger().info(f'Published actions: {actions[0]}')

def main(args=None):
    rclpy.init(args=args)
    node = XR1DeploymentNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

---

## å…­ã€æ•…éšœæ’æŸ¥

### 6.1 æ¨¡å‹åŠ è½½å¤±è´¥

```bash
# é”™è¯¯: ModuleNotFoundError: No module named 'lerobot'

# è§£å†³: ç¡®ä¿åœ¨xr1ç¯å¢ƒä¸­
source /home/leo/miniconda3/etc/profile.d/conda.sh
conda activate xr1

# éªŒè¯å®‰è£…
python -c "import lerobot; print('âœ… LeRobotå·²å®‰è£…')"
```

### 6.2 CUDAå†…å­˜ä¸è¶³

```python
# é”™è¯¯: RuntimeError: CUDA out of memory

# è§£å†³1: å‡å°‘batch_size
--batch_size=8  # é»˜è®¤20ï¼Œå‡å°åˆ°8

# è§£å†³2: ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
--mixed_precision=fp16

# è§£å†³3: å‡å°‘action_horizon
--policy.action_chunk_size=30  # é»˜è®¤50
```

### 6.3 å›¾åƒé¢„å¤„ç†é”™è¯¯

```python
# é”™è¯¯: å›¾åƒå°ºå¯¸ä¸åŒ¹é…

# è§£å†³: æ£€æŸ¥å›¾åƒé¢„å¤„ç†æµç¨‹
# 1. ç¡®ä¿å›¾åƒresizeåˆ° (640, 480)
# 2. ç¡®ä¿å½’ä¸€åŒ–åˆ° [0, 1]
# 3. ç¡®ä¿ç»´åº¦ä¸º [1, 3, H, W]
```

### 6.4 ROS2è¿æ¥å¤±è´¥

```bash
# é”™è¯¯: æ— æ³•è¿æ¥åˆ°æœºå™¨äºº

# æ£€æŸ¥1: ç½‘ç»œé…ç½®
ping 192.168.41.1
ip addr show enp1s0f0np0

# æ£€æŸ¥2: ROS2ç¯å¢ƒ
source ~/activate_ros2.sh
ros2 topic list

# æ£€æŸ¥3: æœºå™¨äººæ˜¯å¦å¯åŠ¨
ssh ubuntu@192.168.41.1
ros2 node list
```

---

## ğŸ“š å‚è€ƒèµ„æº

- **XR-1 GitHub**: https://github.com/Open-X-Humanoid/XR-1
- **RoboMINDæ•°æ®é›†**: https://huggingface.co/datasets/x-humanoid-robomind/RoboMIND
- **LeRobotæ–‡æ¡£**: https://github.com/huggingface/lerobot
- **ROS2 Humble**: https://docs.ros.org/en/humble/

---

## ğŸ“ æ›´æ–°æ—¥å¿—

| æ—¥æœŸ | ç‰ˆæœ¬ | æ›´æ–°å†…å®¹ |
|------|------|----------|
| 2026-02-02 | v1.0 | åˆå§‹ç‰ˆæœ¬ï¼ŒåŒ…å«æ¨ç†ã€å¾®è°ƒã€éƒ¨ç½²å®Œæ•´æµç¨‹ |

---

**æ–‡æ¡£ç»´æŠ¤**: DGX Sparkå¼€å‘ç¯å¢ƒ  
**é—®é¢˜åé¦ˆ**: è¯·åœ¨GitHub Issuesä¸­æäº¤
